{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='steelblue'>\n",
    "\n",
    "## MNIST Digit Recognition\n",
    "  <br>  \n",
    "<font size = 4>\n",
    "- From the Keras datasets, import the MNIST Digits data.<br>\n",
    "- There are images of digits 0 to 9 and have labels associated\n",
    "    with each image.<br>\n",
    "</font>\n",
    "</font>\n",
    "\n",
    "<font color = 'grey'>\n",
    "<font size = 3>\n",
    "    \n",
    "### Following examples are included in the processing:\n",
    "1. Check the version of Tensorflow and Keras\n",
    "2. Load training and test data including labels\n",
    "3. Normalize the images\n",
    "4. Plot few images after being normalized\n",
    "5. Create a Neural Network and build a model\n",
    "6. Train the model on the training dataset\n",
    "7. Evaluate the accuracy of the model using test dataset\n",
    "8. Plot the accuracy and loss for the model\n",
    "9. Introduction to tensorflow `\"Callbacks\"`    \n",
    "</font>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%config IPCompleter.greedy = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure tensorflow is properly installed\n",
    "tf.__version__, tf.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_mnist = keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "                                digits_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size: train images {}, train labels {}\".format(train_images.shape, \n",
    "                                                      train_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size: test images {}, test labels {}\".format(test_images.shape, \n",
    "                                                      test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at first 10 labels in training set\n",
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure\n",
    "plt.imshow(train_images[5], cmap=plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the values to be between 0 and 1; min-max normalization\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot few normalized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view 25 images in grayscale\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)      # print 5 images per row\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap = plt.cm.binary)\n",
    "    plt.xlabel(train_labels[i]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Network\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative way to instantiate and create a Sequential() neural network\n",
    "\n",
    "def makeModel(modelName = \"\"):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(128, activation='relu', name = \"FirstLayer\"),\n",
    "        keras.layers.Dense(10, activation='softmax', name = \"Output\")\n",
    "        ], name = modelName)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Alternative way to instantiate and create a Sequential() neural network\n",
    "\n",
    "# Initialize the first weights\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "def makeModel(modelName = \"\"):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(128, activation='relu', name = \"FirstLayer\",\n",
    "                           kernel_initializer = 'random_normal',\n",
    "                           bias_initializer='zeros',),\n",
    "        keras.layers.Dense(10, activation='softmax', name = \"Output\")\n",
    "        ], name = modelName)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2345)\n",
    "\n",
    "# Compile the model with chosen parameters\n",
    "\n",
    "model = makeModel(\"FirstModel\")\n",
    "model.compile(optimizer='adam', # keras.optimizers.Adam(learning_rate=0.001)\n",
    "              loss='sparse_categorical_crossentropy',    # discrete numbers 0 - 9\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.random.set_seed(2345)\n",
    "\n",
    "# Train the model and include a validation set (composed of 10% of the dataset)\n",
    "# Capturing the returned history enables you to plot the change in \n",
    "# error/loss and accuracy over time\n",
    "\n",
    "history = model.fit(train_images, train_labels, validation_split=0.1, \n",
    "                    epochs=15, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = model.metrics_names\n",
    "metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the accuracy of the model\n",
    "\n",
    "- Evaluate to see the accuracy and loss\n",
    "- Plot the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the test images to evaluate the model on a set of unseen images\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Test Loss: \", test_loss)\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string1, string2):\n",
    "    # 2 rows 1 column\n",
    "    plt.subplots(2, 1, sharex=False, sharey=False, figsize = (8,6))\n",
    "\n",
    "    # plot 1\n",
    "    plt.subplot(211)\n",
    "    plt.plot(history.history[string1])\n",
    "    plt.plot(history.history['val_'+string1])\n",
    "    plt.ylabel(string1)\n",
    "    plt.legend([string1, 'val_'+string1]);\n",
    "    \n",
    "    # plot 2\n",
    "    plt.subplot(212)\n",
    "    plt.plot(history.history[string2])\n",
    "    plt.plot(history.history['val_'+string2])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(string2)\n",
    "    plt.legend([string2, 'val_'+string2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, metrics_names[0], metrics_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on test data\n",
    "\n",
    "- Make predictions on the test images\n",
    "- Plot correct and incorrect predictions\n",
    "- Create Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preds currently has the probability for each of the 10000 test images\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction for each image\n",
    "preds = np.argmax(preds, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 10 predictions\n",
    "fig, axes = plt.subplots(ncols=10, sharex=False,\n",
    "                         sharey=True, figsize=(20, 4))\n",
    "for i in range(10):\n",
    "    axes[i].set_title(preds[i])\n",
    "    axes[i].imshow(test_images[i], cmap='gray')\n",
    "    axes[i].get_xaxis().set_visible(False)\n",
    "    axes[i].get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of correct predictions: {}\".format(len(preds[preds == test_labels])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of incorrect predictions: {}\".format(len(preds[preds != test_labels])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (8,6))\n",
    "sn.heatmap(cm, annot=True, cmap=plt.cm.Blues, fmt = 'g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the first 10 incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=10, sharex=False,\n",
    "                         sharey=True, figsize=(20, 4))\n",
    "count = 0\n",
    "for i in range(10000):\n",
    "    if preds[i] != test_labels[i]:\n",
    "        axes[count].set_title(preds[i])\n",
    "        axes[count].imshow(test_images[i], cmap='gray')\n",
    "        axes[count].get_xaxis().set_visible(False)\n",
    "        axes[count].get_yaxis().set_visible(False)\n",
    "        count = count + 1\n",
    "        if count == 10:\n",
    "            break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Points\n",
    "\n",
    "**How long should the model be trainied?**\n",
    "\n",
    "- Often it depends on the problem and data, sometimes the model trains very fast other times it takes a while\n",
    "- Also the validation loss and validation accuracy keeps bouncing from epoch to epoch\n",
    "- This is where the check points come in and there are many different types\n",
    "- Look at the Model Check point, saving the best model from all the epochs used\n",
    "\n",
    "<font size = \"3\">\n",
    "    \n",
    "[Check callbacks documentation](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback)\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a function to implement a ModelCheckpoint callback with \n",
    "# a specific filename\n",
    "\n",
    "# define folder to store model\n",
    "folderName = \"ModelExperiments\"\n",
    "\n",
    "def create_model_checkpoint(model_name, save_path = folderName):\n",
    "    '''\n",
    "    Create a model check point, provide model name and path\n",
    "    '''\n",
    "    return tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(save_path, model_name), # create filepath to save model\n",
    "        verbose=1,                                    # only output a limited amount of text\n",
    "        save_best_only=True)                          # save only the best model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model that will use the check point\n",
    "\n",
    "tf.random.set_seed(2345)\n",
    "\n",
    "model1 = makeModel(\"WithCheckpoint\")\n",
    "model1.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.random.set_seed(2345)\n",
    "\n",
    "# train the model and provide a check point\n",
    "history1 = model1.fit(train_images, train_labels, validation_split=0.1, \n",
    "                      epochs=15, verbose = 1,\n",
    "                      callbacks = [create_model_checkpoint(model_name = model1.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metrics for the best saved model\n",
    "plot_graphs(history1, metrics_names[0], metrics_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model1.evaluate(test_images, test_labels)\n",
    "print(\"Test Loss: \", test_loss)\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = folderName + \"/\" + model1.name\n",
    "model1 = tf.keras.models.load_model(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model1.evaluate(test_images, test_labels)\n",
    "print(\"Test Loss: \", test_loss)\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Here are couple of other examples\n",
    "\n",
    "%%time\n",
    "history1 = model1.fit(train_images, train_labels, validation_split=0.1, \n",
    "                    epochs=15, verbose = 1,\n",
    "                   callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                       monitor = \"val_loss\", \n",
    "                       patience = 3,\n",
    "                   restore_best_weights = True),\n",
    "                               tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                                   monitor=\"val_loss\", \n",
    "                                   patience=100, verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Comic sans MS; font-size:1.4em;\">\n",
    "<font color='tomato'>\n",
    "    <h2>Practice</h2>\n",
    "    <h3>Try out different parameters and see how model accuracy changes</h3>\n",
    "    <ol>\n",
    "        <li>Don't normalize the pixel values, see what happens</li>\n",
    "        <li>Play with different epoch values (10, 20, ...)</li>\n",
    "        <li>Modify the number of neurons in the Dense (hidden) layer following the Flatten layer. Try numbers as low as 10 and as high as 512 and note the effect on accuracy and training time</li>\n",
    "        <li>Add an additional Dense (hidden) layer before the final Dense (output) layer, and experiment with different numbers of neurons in the layer</li>\n",
    "        <li>Modify the learning rate and observe the impact it has on the training time and the accuracy of the model</li>    \n",
    "    </ol>\n",
    "</font>\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "308px",
    "width": "514px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
